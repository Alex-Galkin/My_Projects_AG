{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Задача работы - построить скоринг-модель для вторичных клиентов банка, которая бы предсказывала вероятность дефолта клиента"},{"metadata":{},"cell_type":"markdown","source":"Описания полей\n\n* client_id - идентификатор клиента\n\n* education - уровень образования\n\n* sex - пол заемщика\n\n* age - возраст заемщика\n\n* car - флаг наличия автомобиля\n\n* car_type - флаг автомобиля иномарки\n\n* decline_app_cnt - количество отказанных прошлых заявок\n\n* good_work - флаг наличия “хорошей” работы\n\n* bki_request_cnt - количество запросов в БКИ\n\n* home_address - категоризатор домашнего адреса\n\n* work_address - категоризатор рабочего адреса\n\n* income - доход заемщика\n\n* foreign_passport - наличие загранпаспорта\n\n* sna - связь заемщика с клиентами банка\n\n* first_time - давность наличия информации о заемщике\n\n* score_bki - скоринговый балл по данным из БКИ\n\n* region_rating - рейтинг региона\n\n* app_date - дата подачи заявки\n\n* default - флаг дефолта по кредиту"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Импортируем библиотеки"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pandas import Series\nimport random\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, RobustScaler\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import auc, roc_auc_score, roc_curve\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n\nimport operator\n\nimport calendar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Избавляемся от предупреждений\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def diagram_bar(data, column):\n    '''\n     Функция построения гистограммы и boxplot в одном окне\n     \n     Входные параметры: data - датафрейм, \n                        column - признак (столбец), по которому строятся графики\n    '''\n    fig = plt.figure()\n    main_axes = fig.add_axes([0,0,1,1])\n    data[column].hist(bins = 20)  # Построение гистограммы\n    \n    insert_axes = fig.add_axes([1.1,0,0.5,1])\n    data.boxplot(column = column)  # Построение boxplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_visual(predict, pro_babs, X_tst, y_tst):\n    ''' \n    Функция визуализации результатов работы модели: метрики, confusion matrix, ROC-AUC\n    \n    Входные параметры:  predict - массив предсказанных значений целевой переменной\n                        pro_babs - вероятность принадлежности предсказанных значений целевой переменной к имеющимся классам\n                        X_tst - массив тестовых значений признаков\n                        y_tst - массив тестовых значений целевой переменной\n    '''   \n    # Печать отчета о классификации\n    print(classification_report(y_tst, predict))\n    \n    # Печать confusion matrix\n    conf_mat = confusion_matrix(predict, y_test)\n    print('Confusion matrix:\\n{}'.format(conf_mat))\n    \n    # Визуализация confusion matrix\n    class_names = ['not_default', 'default']\n    df_cm = pd.DataFrame(conf_mat, index=class_names, columns=class_names)\n    plt.figure(figsize = (10,5))\n    sns.heatmap(df_cm, annot=True, fmt=\"d\");\n    \n    # Построение графика ROC-AUC\n    pro_babs = pro_babs[:,1]\n\n    fpr, tpr, threshold = roc_curve(y_test, pro_babs)\n    roc_auc = roc_auc_score(y_test, pro_babs)\n\n    plt.figure(figsize=(20,10))\n    plt.plot([0, 1], label='Baseline', linestyle='--')\n    plt.plot(fpr, tpr, label = 'Regression')\n    plt.title('Logistic Regression ROC AUC = %0.5f' % roc_auc)\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.legend(loc = 'lower right')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clear_sign_num(df_, sign):\n    '''\n     Функция очиски количественных признаков от выбросов\n     \n     Входные параметры: df_ - датасет\n                        sign - признак, по которому делается очистка\n    '''\n    for i in range(2): \n        sign_dscrb = df_[df_.default == i][sign].describe()\n        delta = (sign_dscrb[6] - sign_dscrb[4])*1.5 # Рассчитываем межквартильный порог\n        top_board = sign_dscrb[6] + delta # Верхняя граница выбросов\n        bot_board = sign_dscrb[4] - delta # Нижняя граница выбросов\n        \n        # Очищаем по нижней границе\n        df_.drop(df_[df_.default == i][(df_[sign] < bot_board)].index, axis= 0, inplace= True) \n    \n        # Очищаем по верхней границе     \n        df_.drop(df_[df_.default == i][(df_[sign] > top_board)].index, axis= 0, inplace= True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def G_S_CV(model_entr, param_grid, X_trn, y_trn, X_tst, y_tst):\n    '''\n     Функция подбора гиперпараметров, построения оптимизированной модели логистической регрессии и отображения результатов\n     \n     Входные данные: model_entr - оптимизируемая модель\n                     param_grid - ограничения для параметра регуляризации и гиперпараметры\n                     X_trn - массив тренировочных значений признаков\n                     y_trn - массив тренировочных значений целевой переменной\n                     X_tst - массив тестовых значений признаков\n                     y_tst - массив тестовых значений целевой переменной\n    \n    Возвращает регуляризированную модель с оптимальными параметрами\n    '''\n    # Подбор параметров\n    model_tmp = GridSearchCV(model_entr, param_grid, scoring='f1', n_jobs=-1, cv=5)\n\n\n    # Обучение модели\n    model_tmp.fit(X_trn, y_trn)\n    model_exit = model_tmp.best_estimator_  # Запоминание оптимальных параметров\n\n    # Печать параметров\n    best_parameters = model_exit.get_params()\n    for param_name in sorted(best_parameters.keys()):\n        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n        \n    # Предсказание целевой переменной\n    preds = model_exit.predict(X_tst)\n    \n    # Вероятность принадлежности предсказанных значений целевой переменной к имеющимся классам\n    probs = model_exit.predict_proba(X_tst)\n    \n    # Визуализация результатов\n    model_visual(preds, probs, X_tst, y_tst)\n    \n    return model_exit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Фиксируем RANDOM_SEED\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Загружаем данные"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-scoring/'\ndf_train = pd.read_csv(DATA_DIR+'/train.csv')\ndf_test = pd.read_csv(DATA_DIR+'test.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Проверяем загруженные данные"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Тренировочный датасет\ndf_train.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Тестовый датасет\ndf_test.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Файл \"sample_submission\"\nsample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Общая информация о тренировочном датасете\ndf_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### В тренировочном датасете имеем 73799 записей (наблюдений) и 18 признаков: 6 строковых и 12 числовых, а также 1 целевая переменная"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем наличие пропущенных значений\ndf_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### В тренировочном датасете имеется 307 пропущенных значений только в одном признаке - \"education\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим количество недефолтных (0) и дефолтных (1) заёмщиков\ndf_train.default.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\ndf_train.default.value_counts().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Количество \"дефолтных\" заёмщиков превышает 10% \"недефолтных\", поэтому можно считать данную выборку сбалансированной"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Общая информация о тестовом датасете\ndf_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### В тестовом датасете имеем 36349 записей (наблюдений) и 18 признаков: 6 строковых и 12 числовых (как и в тренировочном датасете)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем наличие пропущенных значений\ndf_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### В тестовом датасете, как и тренировочном, имеются пропущенные значения только в одном признаке - \"education\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для корректной обработки признаков объединяем тренировочный и тестовый датасеты в один датасет\ndf_train['sample'] = 1  # Помечаем где у нас трейн\ndf_test['sample'] = 0   # Помечаем где у нас тест\ndf_test['default'] = 0  # В тесте у нас нет значения default, поэтому мы его просто заполняем нулями\n\ndf = df_test.append(df_train, sort=False).reset_index(drop=True) # Объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем результат\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Обработка и очистка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Общая информация об объединённом датасете\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем наличие пропущенных значений\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Всего имеется 478 пропущенных значений в признаке \"education\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем наличие пустых записей\ndf[df_test == ''].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Пустых записей нет"},{"metadata":{},"cell_type":"markdown","source":"#### В датасете имеется 478 пропущенных значений в признаке \"education\", что составляет менее 0.5% от общего числа записей. Данные записи, всилу их малого количества, теоретически можно исключить из дальнейшей обработки, но тогда мы потеряем часть записей из тестового набора данных, которые в конечном итоге мы должны предсказать, что не очень хорошо. Тогда заполним пропущенные данные. Предполагаем, что уровень зарплаты сильно зависит от уровня образования, а также от возраста заемщика"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим распределение признака \"education\"\nplt.figure(figsize=(10, 5))\ndf.education.value_counts().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Проверяем зависимость уровня образования от возраста и заработной платы"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим значимость признаков 'age' и 'income' для уровня образования\ndf_tmp = df.dropna()\nplt.rcParams['figure.figsize'] = (10,5)\nimp_num = Series(f_classif(df_tmp[['age', 'income']], df_tmp['education'])[0], index = ['age', 'income'])\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Признак 'income' является более значимым"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Графики Boxplot \"education-income\"\nplt.figure(figsize=(15, 10))\nsns.boxplot(x=\"education\", y=\"income\", data=df, showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Графики Boxplot \"education-age\"\nplt.figure(figsize=(15, 10))\nsns.boxplot(x=\"education\", y=\"age\", data=df, showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Резюме: \n#### Пропущенные значения признака \"education\" будем заполнять, в зависимости от заработной платы (признак \"income\") по принципу \"выше или равно\" медианному значению конкретного уровня обучения (при заполнении пропущенных значений признака \"education\" в зависимости от возраста метрики получаются чуть хуже)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Модуль заполнения пропущенных значений признака \"education\" в зависимости от зарплаты\n\nedu_encome = {}  # Создаём словарь \"образование - медиана зарплаты\"\n\n# Заполняем словарь медианными значениями уровня зарплаты (\"income\") в зависимости от уровня образования (\"education\")\nfor edu in df.education.value_counts().index:\n    edu_encome[edu] = df[df.education == edu].income.median() # Заполнение словаря\n    \n# Сортируем словарь по убыванию значений зарплаты\nee_sort = sorted(edu_encome.items(),key = operator.itemgetter(1),reverse = True)\n\n# Заполняем пропуски в признаке \"education\"\nfor ind in df[df.education.isna()].index:\n    for i, j in ee_sort:\n        if df.iloc[ind].income >= j: \n            df.loc[ind, 'education'] = i\n            break\n\n# Заполняем оставшиеся пропуски значением \"UGR\"\ndf.education.fillna('UGR', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем результат\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### В датасете есть признак \"app_date\" - дата подачи заявки, имеющий тип \"object\". Преобразуем его в формат \"datetime\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df['app_date'] = pd.to_datetime(df.app_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим диапазон дат\nprint(df['app_date'].min())\nprint(df['app_date'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Диапазон дат поданных заявок охватывает период за четыре месяца с начала года. \n#### Преобразуем данный признак в число дней, прошедших с начала года (с момента подачи первой заявки)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Запомним на всякий случай наши данные\ndate_app = df['app_date']\n\nstart_date = df['app_date'].min()  # Минимальное значение дат\ndf['app_date'] = df['app_date'].apply(lambda x: (x - start_date).days)  # Преобразование столбца","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем результат\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим распределение преобразованного признака \"app_date\"\ndf['app_date'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\ndiagram_bar(df, 'app_date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns_plot = sns.distplot(df['app_date'])\nfig = sns_plot.get_figure()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Очень похоже на равномерное распределение"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим распределение признака \"client_id\"\nsns_plot = sns.distplot(df['client_id'])\nfig = sns_plot.get_figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['client_id'].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Признак \"client_id\" имеет абсолютно равномерное распределение, по сути является порядковым номером клиента и в состав признаков для построения модели включаться не будет"},{"metadata":{},"cell_type":"markdown","source":"#### Распределим наши данные на цифровые, категориальные и бинарные переменные"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Таким образом, для построения модели мы берём 17 признаков:\n\n# К цифровым (числовым) относится 6 признаков:\nnum_cols = ['app_date', 'age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income']\n\n# К категориальным относится 6 признаков:\ncat_cols = ['education', 'region_rating', 'home_address', 'work_address', 'sna', 'first_time']\n\n# К бинарным относится 5 признаков:\nbin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Работа с числовыми призаками"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим распределение цифровых признаков\nfor i in df[num_cols]:\n    plt.figure(figsize=(10,5))\n    sns.distplot(df[i], kde = False, color='r')\n    plt.title(i)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### У четырёх из шести признаков:  \"age\", \"income\", \"decline_app_cnt\" и \"bki_request_cnt\" имеются не очень хорошие \"правые хвосты\". Логарифмирование данных признаков может поправить положение только у двух из них: \"age\" и \"income\". Для признаков \"decline_app_cnt\" и \"bki_request_cnt\" логарифмирование вряд ли поможет, так как у них имеется слишком много нулевых значений"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['decline_app_cnt'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['bki_request_cnt'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразуем все числовые переменные в логарифмические функции\nfor i in num_cols:\n    df[i] = np.log1p(df[i].abs())\n    plt.figure(figsize=(10,5))\n    sns.distplot(df[i][df[i] > 0].dropna(), kde = False, rug=False, color='b')\n    plt.title(i)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### В распределении признаков \"age\" и \"score_bki\" произошло небольшое смещение вправо, распределение признака \"income\" стало нормальным"},{"metadata":{},"cell_type":"markdown","source":"#### Посмотрим наличие выбросов у числовых признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Визуализация числовых переменных с использованием графика boxplot\nfig, axes = plt.subplots(2, 3, figsize=(20,15))\nplt.subplots_adjust(wspace = 0.5)\naxes = axes.flatten()\nfor i in range(len(num_cols)):\n    sns.boxplot(x=\"default\", y=num_cols[i], data=df, orient = 'v', ax=axes[i], showfliers=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Из полученных графиков можно сделать следующие выводы:\n#### Пять из шести числовых параметров имеют множественные выбросы\n#### Дефолтные клиенты в среднем немного младше недефолтных\n#### Дефолтные клиенты в среднем имеют немногим более низкий доход\n#### Дефолтные клиенты в среднем имеют бОльшее количество отмененных заявок\n#### Дефолтные клиенты в среднем имеют больше запросов в БКИ\n#### Дефолтные клиенты в среднем имеют более низкий в абсолютной величине скоринговый балл"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оценим корреляцию Пирсона для непрерывных переменных\nplt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(df[num_cols].corr().abs(), vmin=0, vmax=1, annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Выводы:\n#### Числовые признаки слабо коррелированы друг с другом. Наибольшая корреляция наблюдается между признаками \"score_bki\" (скоринговый балл), \"decline_app_cnt\" (количество отказов) и \"bki_request_cnt\" (количество обращений в БКК). Все числовые признаки оставляем для дальнейшей работы"},{"metadata":{},"cell_type":"markdown","source":"#### Оценим значимость числовых переменных для целевого признака \"default\" с помощью функции f_classif. В качестве меры значимости используем значение f-статистики"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,5)\nimp_num = Series(f_classif(df[num_cols], df['default'])[0], index = num_cols)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Выводы:\n#### Из числовых признаков наибольшее влияние на целевую переменную оказывают признаки \"score_bki\" (скоринговый балл) и \"decline_app_cnt\" (количество отказов), наименьшее - \"age\" (возраст) и \"app_date\" (дата подачи заявки)"},{"metadata":{},"cell_type":"markdown","source":"### Работа с бинарными признаками"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для бинарных признаков используем LabelEncoder\nmap_categories = {}  # Создаём словарь кодировок\n\nlabel_encoder = LabelEncoder()\n\nfor column in bin_cols:  # Организуем цикл по бинарным признакам и формируем словарь\n    df[column] = label_encoder.fit_transform(df[column])\n    map_categories[column] = dict(enumerate(label_encoder.classes_)) # Запоминаем, что закодировали","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем словарь\nmap_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Убеждаемся в преобразовании    \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Работа с категориальными признаками"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для двух категориальных признаков: \"education\" и \"region_rating\" первоначальнор используем LabelEncoder\nfor name in ['education', 'region_rating']:\n    df[name] = label_encoder.fit_transform(df[name])\n    map_categories[name] = dict(enumerate(label_encoder.classes_)) # Запоминаем, что закодировали","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем словарь\nmap_categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Для оценки значимости категориальных и бинарных переменных используем функцию mutual_info_classif"},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_cat = Series(mutual_info_classif(df[bin_cols + cat_cols], df['default'],\n                                     discrete_features =True), index = bin_cols + cat_cols)\nimp_cat.sort_values(inplace = True)\nimp_cat.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Выводы:\n#### Из категориальных признаков самыми значимыми являются признаки \"sna\" (связь заемщика с клиентами банка) и \"first_time\" (давность наличия информации о заемщике), наименее значимыми - \"sex\" (пол заёмщика)"},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим зависимости между признаками"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_bin_cols = cat_cols + bin_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Зарплата - категорийные переменные\nfig, axes = plt.subplots(4, 3, figsize=(20,25))\nplt.subplots_adjust(wspace = 0.5)\naxes = axes.flatten()\nfor i in range(len(cat_bin_cols)):\n    sns.boxplot(x=cat_bin_cols[i], y=\"income\", data=df, orient = 'v', ax=axes[i], showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Скоринговый бал - категорийные переменные\nfig, axes = plt.subplots(4, 3, figsize=(20,25))\nplt.subplots_adjust(wspace = 0.5)\naxes = axes.flatten()\nfor i in range(len(cat_bin_cols)):\n    sns.boxplot(x=cat_bin_cols[i], y=\"score_bki\", data=df, orient = 'v', ax=axes[i], showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ввозраст - категорийные переменные\nfig, axes = plt.subplots(4, 3, figsize=(20,25))\nplt.subplots_adjust(wspace = 0.5)\naxes = axes.flatten()\nfor i in range(len(cat_bin_cols)):\n    sns.boxplot(x=cat_bin_cols[i], y=\"age\", data=df, orient = 'v', ax=axes[i], showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Выводы:\n#### 1. Уровень запрплаты в среднем не зависит от уровня образования\n#### 2. Чем выше рейтинг региона, тем в среднем выше уровень зарплаты\n#### 3. Уровень зарплаты практически не зависит от адреса проживания и работы\n#### 4. Чем выше уровень зарплаты, тем ниже индекс связи заемщика с клиентами банка\n#### 5. Чем выше уровень зарплаты, тем выше признак давности наличия информации о заемщике\n#### 5. Клиенты мужского пола в среднем получают более высокую зарплату\n#### 6. Клиенты с болеее высокой зарплатой чаще имеют машину, у них есть хорошая работа, они чаще выезжают за границу (на отдых)\n#### 7. Чем выше индекс образования, тем, в-среднем, ниже скоринговый балл\n#### 8. Скоринговый балл не зависит от адреса проживания и работы, рейтинга региона и индекса связи заемщика с клиентами банка\n#### 9. Чем выше значение индекса давности наличия информации о заемщике, тем, в-среднем, выше скоринговый балл\n#### 10. Более молодые клиенты предпочитают проживать в регионах с более высоким рейтингом\n#### 11. Среди клиентов мужчины раньше начинают обращаться в банки, также мужчины раньше покупают машину, получают хорошую работу и оформляют загранпаспорт"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_copy = df.copy()  # Запоминаем на всякий случай датасет до \"get_dummies\"\n\n# \"Оцифровываем\" категориальные переменные\nfor sign in cat_cols:\n    df = pd.get_dummies(df, columns=[sign])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем результат  \ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оценим корреляцию Пирсона для всех признаков преобразованного датасета\nplt.rcParams['figure.figsize'] = (45,30)\nsns.heatmap(df.corr().abs(), vmin=0, vmax=1, annot = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Выводы:\n#### Высокая корреляция (>0.7) наблюдается между следующими признаками:\n#### 1. \"client_id\" и \"app_date\" = 1.0. Исключим из модели признак \"client_id\"\n#### 2. \"home_address_1\" и \"home_address_2\" = 0.97\n#### 3. \"home_address_1\" и \"work_address_3\" = 0.82\n#### 4. \"home_address_2\" и \"work_address_3\" = 0.80\n#### 5. \"work_address_2\" и \"work_address_3\" = 0.78\n#### 6. \"education_1\" и \"education_3\" = 0.72\n#### 7. \"car\" и \"car_type\" = 0.70\n#### Посмотрим влияние данных признаков на поведение модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Смотрим общую информацию по преобразованному датасету\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Подготовка данных к машинному обучению"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиваем датасет на тренировочный и тестовый, удалив лишние столбцы\ntrain_data = df.query('sample == 1').drop(['sample', 'client_id'], axis=1)  # Тренировочный\ntest_data = df.query('sample == 0').drop(['sample', 'default'], axis=1)     # Тестовый\n\n# Сохраняем ID клиентов из тестового набора для  формирования Submission\nid_test = test_data['client_id']\n\n# Удаляем ID клиентов из тестового набора для последующего формирования признакового проостранства\ntest_data.drop(['client_id'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape, test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Стандартизировать числовые переменные будем методом \"StandardScaler\", так как метод \"RobustScaler\" показал несколько худшие результаты"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Тренировочный датасет\nX_num_train = StandardScaler().fit_transform(train_data[num_cols].values)\n#X_num_train = RobustScaler().fit_transform(train_data[num_cols].values)\n\n# Тестовый датасет\nX_num_test = StandardScaler().fit_transform(test_data[num_cols].values)\n#X_num_test = RobustScaler().fit_transform(test_data[num_cols].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Формируем датасеты с категориальными переменными\n\n# Тренировочный датасет\ndf_cat_train = train_data.drop([\"default\"], axis = 1)\ndf_cat_train.drop(num_cols, axis = 1, inplace = True)\n\n# Тестовый датасет\ndf_cat_test = test_data.drop(num_cols, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Объединяем цифровые, бинарные и категориальные оцифрованные признаки в одну матрицу (в одно признаковое пространство)\n\n# Тренировочные данные\nX_1 = np.hstack([X_num_train, df_cat_train.values])\n\n# Тестовые данные\nX_t_1 = np.hstack([X_num_test, df_cat_test.values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Целевая переменная\ny_1 = train_data['default'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_1.shape, X_t_1.shape, y_1.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## МОДЕЛЬ № 1 (базовая)"},{"metadata":{},"cell_type":"markdown","source":"### Первую (базовую) модель построим по всем признакам без фильтрации"},{"metadata":{},"cell_type":"markdown","source":"### Обучение модели логистической регрессии"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиваем данные на тренировочную и тестовую части\nX_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size=0.20, shuffle = True, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Строим и обучаем модель\nmodel_1 = LogisticRegression(multi_class = 'ovr', class_weight='balanced', solver='liblinear', random_state=RANDOM_SEED)\nmodel_1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предсказываем целевую переменную и вероятностные оценки\ny_pred = model_1.predict(X_test)\nprobs = model_1.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### В качестве метода оценки прогностической способности модели используем ROC-анализ"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Визуализация результатов\nmodel_visual(y_pred, probs, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ВЫВОДЫ (модель №1):\n### Дефолтные клиенты угадываются достаточно неплохо: 1245 из 1827 (68%), при этом угадывание недефолтных клиентов составляет 67% (8692 из 12933). Значение ROC AUC достаточно высокое - 0.74328.\n### Данная модель примерно одинаково предсказывает дефолтных и недефолтных клиентов"},{"metadata":{},"cell_type":"markdown","source":"## МОДЕЛЬ № 1.1 (базовая + регуляризация)[](http://)"},{"metadata":{},"cell_type":"markdown","source":"### Подбор гиперпараметров для модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Ограничения для параметра регуляризации \n#C = np.logspace(0, 4, 5)\nC = [0.1, 1, 10]\n\n# ... и гиперпараметры\niter_ = 150\nepsilon_stop = 1e-4\n\nparam_grid_1 = [\n    {'penalty': ['l1'], 'C': C, 'max_iter':[iter_],'tol':[epsilon_stop]},\n    {'penalty': ['l2'], 'C': C, 'max_iter':[iter_],'tol':[epsilon_stop]},\n    {'penalty': ['none'], 'max_iter':[iter_],'tol':[epsilon_stop]},\n               ]\n\nparam_grid_2 = [\n    {'penalty': ['l1'],\n     'C': C,\n     'solver': ['liblinear', 'lbfgs'], \n     'class_weight':['none', 'balanced'], \n     'multi_class': ['auto','ovr'], \n     'max_iter':[iter_],\n     'tol':[epsilon_stop]},\n    {'penalty': ['l2'], \n     'C': C,\n     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n     'class_weight':['none', 'balanced'], \n     'multi_class': ['auto','ovr'], \n     'max_iter':[iter_],\n     'tol':[epsilon_stop]},\n    {'penalty': ['none'], \n     'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], \n     'class_weight':['none', 'balanced'], \n     'multi_class': ['auto','ovr'], \n     'max_iter':[iter_],\n     'tol':[epsilon_stop]},\n              ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Регуляризация построенной модели с подбором гиперпараметров param_grid_1\nmodel_1_1 = G_S_CV(model_1, param_grid_1, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Регуляризация построенной модели с подбором гиперпараметров param_grid_2\n#model_1_2 = G_S_CV(model_1, param_grid_2, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ВЫВОДЫ (модель № 1.1):\n### Значения всех метрик остались без изменения"},{"metadata":{},"cell_type":"markdown","source":"## Модель № 2 (подбор оптимального состава признаков)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Исключаем из построения модели из состава числовых данных малозначимые признаки \"app_date\" и \"age\"\nnum_cols_no_date = ['age', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income']\nnum_cols_no_age = ['app_date', 'decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income']\nnum_cols_no_da = ['decline_app_cnt', 'score_bki', 'bki_request_cnt', 'income']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Исключение из модели любого числового признака приводит к ухудшению её предсказательной способности. По этой причине числовые признаки оставляем в модели все"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Стандартизируем числовые переменные \n#X_num_train = StandardScaler().fit_transform(train_data[num_cols].values)  # Тренировочный датасет\n#X_num_train = RobustScaler().fit_transform(train_data[num_cols].values)\n\n#X_num_test = StandardScaler().fit_transform(test_data[num_cols].values)    # Тестовый датасет\n#X_num_train = RobustScaler().fit_transform(train_data[num_cols].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Проверка различных гипотез по составу категориальных признаков в модели показал, что лучшие результаты показала модель без признаков \"work_address_3\" и \"home_address_1\", имеющих высокую корреляцию (>0.7) друг с другом и другими переменными. Поэтому, исключаем их из модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Формируем датасеты с категориальными переменными, исключив из их состава признаки,\n# имеющую высокую корреляцию друг с другом: \"work_address_3\" и \"home_address_1\"\n\n# Тренировочный датасет\ndf_cat_train = train_data.drop(num_cols, axis = 1)\ndf_cat_train.drop([\"work_address_3\", \"home_address_1\", 'education_1', \"default\"], axis = 1, inplace = True)\n \n# Тестовый датасет\ndf_cat_test = test_data.drop(num_cols, axis = 1)\ndf_cat_test.drop([\"work_address_3\", \"home_address_1\", 'education_1'], axis = 1, inplace = True)\n\n\n# Объединяем цифровые, бинарные и категориальные оцифрованные признаки в одну матрицу (в одно признаковое пространство)\nX_2 = np.hstack([X_num_train, df_cat_train.values])  # Тренировочные данные\nX_t_2 = np.hstack([X_num_test, df_cat_test.values])  # Тестовые данные\n\n\n# Целевая переменная\ny_2 = train_data['default'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиваем данные на тренировочную и тестовую части\nX_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.20, shuffle = True, random_state=RANDOM_SEED)\n\n\n# Строим и обучаем модель\nmodel_2 = LogisticRegression(multi_class = 'ovr', class_weight='balanced', solver='liblinear', random_state=RANDOM_SEED)\nmodel_2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предсказываем целевую переменную и вероятностные оценки\ny_pred = model_2.predict(X_test)\nprobs = model_2.predict_proba(X_test)\n\n# Визуализация результатов\nmodel_visual(y_pred, probs, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Регуляризация построенной модели с подбором гиперпараметров из param_grid_1\nmodel_2_1 = G_S_CV(model_2, param_grid_1, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Регуляризация построенной модели с подбором гиперпараметров из param_grid_2\n#model_2_2 = G_S_CV(model_2_tmp, param_grid_2, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ВЫВОДЫ (модели №№ 2 и 2.1):\n### Значения метрик относительно модели №1 не ухудшилмсь. Соотношение угадываемых дефолтных и недефолтных клиентов осталось таким же, как и в предыдущих моделях: 68% к 67%. Число угадываемых дефолтных клиентов такое же, как и в модели №1 - 1245. Значение ROC AUC осталось без изменений"},{"metadata":{},"cell_type":"markdown","source":"## Модель №3 (с фильтрацией признаков и очисткой от выбросов)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clear = train_data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### При построении базовой модели (model_1) графики boxplot показали, что пять из шести признаков имеют множественные выбросы. Проведём очистку от выбросов  четырёх из них (очистка признака \"decline_app_cnt\" приводит к удалению слишком большого количества данных, после чего модель показывает не очень хорошие результаты)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Очистка числовых признаков от выбросов\ncolumn = ['app_date', 'score_bki', 'bki_request_cnt', 'income']\nfor i in column:\n    clear_sign_num(df_clear, i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим, на сколько записей уменьшился наш датасет\nprint(len(train_data), len(df_clear), len(train_data) - len(df_clear))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Количество записей уменьшилось на 4831 (6.5%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем результат\nfig, axes = plt.subplots(2, 3, figsize=(20,15))\nplt.subplots_adjust(wspace = 0.5)\naxes = axes.flatten()\nfor i in range(len(num_cols)):\n    sns.boxplot(x=\"default\", y=num_cols[i], data=df_clear, orient = 'v', ax=axes[i], showfliers=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Количество выбросов значительно уменьшилось"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Стандартизируем числовые переменные методом StandardScaler\n\n# Тренировочный датасет\nX_num_train = StandardScaler().fit_transform(df_clear[num_cols].values)\n#X_num_train = RobustScaler().fit_transform(df_clear[num_cols].values)\n\n# Тестовый датасет\n#X_num_test = StandardScaler().fit_transform(test_data[num_cols].values)\n#X_num_test = RobustScaler().fit_transform(test_data[num_cols].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Формируем датасеты с категориальными переменными\n\n# Тренировочный датасет\ndf_cat_train = df_clear.drop(num_cols, axis = 1)\n#df_cat_train.drop([\"default\"], axis = 1, inplace = True)\ndf_cat_train.drop([\"work_address_3\", \"home_address_1\", 'education_1', \"default\"], axis = 1, inplace = True)\n\n# Тестовый датасет\ndf_cat_test = test_data.drop(num_cols, axis = 1)\ndf_cat_test.drop([\"work_address_3\", \"home_address_1\", 'education_1'], axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Объединяем цифровые, бинарные и категориальные оцифрованные признаки в одну матрицу (в одно признаковое пространство)\n\n# Тренировочные данные\nX_3 = np.hstack([X_num_train, df_cat_train.values])\n\n# Тестовые данные\nX_t_3 = np.hstack([X_num_test, df_cat_test.values])\n\n# Целевая переменная\ny_3 = df_clear['default'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиваем данные на тренировочную и тестовую части в соотношении 75% на 25%\nX_train, X_test, y_train, y_test = train_test_split(X_3, y_3, test_size=0.25, shuffle = True, random_state=RANDOM_SEED)\n\nmodel_3 = LogisticRegression(multi_class = 'ovr', class_weight='balanced', solver='liblinear', random_state=RANDOM_SEED)\nmodel_3.fit(X_train, y_train)\n\n# Предсказываем целевую переменную и вероятностные оценки\ny_pred = model_3.predict(X_test)\nprobs = model_3.predict_proba(X_test)\n\n# Визуализация результатов\nmodel_visual(y_pred, probs, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Регуляризация построенной модели с подбором гиперпараметров из param_grid_1\nmodel_3_1 = G_S_CV(model_3, param_grid_1, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Регуляризация построенной модели с подбором гиперпараметров из param_grid_2\n#model_3_2 = G_S_CV(model_3, param_grid_2, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ВЫВОДЫ (модели №№ 3 и 3.1):\n### После проведённой очистки от выбросов четырёх числовых признаков размер датасета уменьшился на 6.5%. При этом, соотношение угадываемых дефолтных и недефолтных клиентов улучшилось и стало равным по 68%. Значение ROC AUC также улучшилось и стало равно 0.74538, причём, регуляризация модели несколько ухудшило значения метрик"},{"metadata":{},"cell_type":"markdown","source":"## Модель №4 (новые признаки)"},{"metadata":{},"cell_type":"markdown","source":"#### Добавим в датасет новые признаки: уровень благосостояния (\"wealthe\", 0-3, зависит от зарплаты), уровень благополучия (\"welfar\", сумма признаков \"wealthe\", \"car\", \"car_type\", \"good_work\", \"region_rating\"), уровень благонадёжности (\"reliability\", сумма \"sna\" и \"first_time\", умноженные на стандартизированные значения \"income\" и \"score_bki\"), активность в банковском секторе (\"activity\", сумма числа запросов в БКИ и числа отказов)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Делаем копию нашего датасета после предобработки\ndf_dop = df_copy.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Новый бинарный признак: запросы в БКИ (0-не было, 1-были)\ndf_dop['bki_req'] = df_dop['bki_request_cnt'].apply(lambda x: 1 if x > 0 else 0)\n\n# Новый бинарный признак: отказы (0-не было, 1-были)\ndf_dop['dec_app'] = df_dop['decline_app_cnt'].apply(lambda x: 1 if x > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Новый бинарный признак: активность в банковском секторе\ndf_dop['activity'] = df_dop['decline_app_cnt'] + df_dop['bki_request_cnt']\nsign_dscrb = df_dop['activity'].describe()\ndf_dop['activity'] = df_dop['activity'].apply(lambda x: 1 if x >= sign_dscrb[5] else 0)\n\n#  Смотрим результат\ndf_dop['activity'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Новый категориальный признак: уровень благосостояния \nsign_dscrb = df_dop['income'].describe()\n\n# \"Оцифровываем\" признак \"income\": 75%<=\"2\" (высокий), 25%<=\"1\"<50% (средний), \"0\"<25% (низкий)\ndf_dop['wealthe'] = df_dop['income'].apply(lambda x: 2 if x >= sign_dscrb[6] else 1 if x >= sign_dscrb[4] else 0)\n\n#  Смотрим результат\ndf_dop['wealthe'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Новый признак: уровень благополучия\ndf_dop['welfare'] = df_dop['car'] + df_dop['car_type'] + df_dop['good_work'] + df_dop['wealthe'] + df_dop['region_rating']\n\n#  Смотрим результат\ndf_dop['welfare'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Попробуем добавить новый категориальный признак - день недели подачи заявки\ntmp = pd.DataFrame(date_app)\ndf_dop['week_day'] = tmp['app_date'].apply(lambda x: calendar.day_abbr[x.date().weekday()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразуем новый признак в числовой вид\n\n# Для нового признака \"week_day\" первоначально используем LabelEncoder\ndf_dop['week_day'] = label_encoder.fit_transform(df_dop['week_day'])\n\n# Запоминаем, что закодировали\nmap_categories['week_day'] = dict(enumerate(label_encoder.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверяем\nmap_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем в список с категориальными признаками новые признаки 'wealthe' и 'welfare'\ncat_cols_new = cat_cols + ['week_day', 'wealthe', 'welfare']\ncat_cols_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем в список с бинарными признаками новый признак \"activity\", \"bki_req\", \"dec_app\"\nbin_cols_new = bin_cols + ['activity', 'bki_req', 'dec_app']\nbin_cols_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим значимость новых категориальных признаков для целевой переменной\nplt.rcParams['figure.figsize'] = (10,10)\nimp_num = Series(f_classif(df_dop[cat_cols_new + bin_cols_new], df_dop['default'])[0], index = cat_cols_new + bin_cols_new)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Новый категориальный признак \"week_day\" оказался ничтожно значимым для целевой переменной, поэтому в состав признаков для построения модели мы его включать не будем. Другие новые признаки оказались достаточно значимыми, их оставим для построения модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем из датасета признак \"week_day\"\ndf_dop.drop(['week_day'], axis = 1, inplace = True)\n\n# Корректируем список с категорийными переменными\ncat_cols_new.remove('week_day')\n\ncat_cols_new","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Новые числовые признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Нормализация признаков \"income\", \"score_bki\", \"decline_app_cnt\", \"bki_request_cnt\"\nfor sign in ['income', 'score_bki', 'decline_app_cnt', 'bki_request_cnt']:\n    sign_n = sign + '_norm'\n    dscrb = df_dop[sign].describe()\n    df_dop[sign_n] = df_dop[sign].apply(lambda x: (x-dscrb[3]) / (dscrb[7] - dscrb[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Новый признак: уровень надёжности\ndf_dop['reliability'] = df_dop['sna']/4 * df_dop['first_time']/4 * (1+df_dop['score_bki_norm']) * (1+df_dop['income_norm'])\n                         # * (1 - df_dop['decline_app_cnt_norm'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем временные признаки 'income_norm', 'score_bki_norm', 'decline_app_cnt_norm'\ndf_dop.drop(['income_norm', 'score_bki_norm', 'decline_app_cnt_norm', 'bki_request_cnt_norm'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём новый список с числовыми признаками\nnum_cols_new = num_cols + ['reliability']\nnum_cols_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим значимость новых числовых признаков для целевой переменной\nplt.rcParams['figure.figsize'] = (10,5)\nimp_num = Series(f_classif(df_dop[num_cols_new], df_dop['default'])[0], index = num_cols_new)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Новый числовые признаки \"reliability\" и \"activity\" оказались достаточно значимыми, их добавим в состав признаков для построения модели"},{"metadata":{},"cell_type":"markdown","source":"#### Таким образом, в наш датасет добавилось 4 новых признака: два категорийных (\"wealthe\" и \"welfare\") и два числовых (\"reliability\" и \"activity\"). Признак \"activity\" является обобщающими признаком двух других: \"decline_app_cnt\" и \"bki_request_cnt\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# \"Оцифровываем\" категориальные переменные\nfor sign in cat_cols_new:\n    df_dop = pd.get_dummies(df_dop, columns=[sign])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оценим корреляцию Пирсона для всех признаков преобразованного датасета\nplt.rcParams['figure.figsize'] = (45,30)\nsns.heatmap(df_dop.corr().abs(), vmin=0, vmax=1, annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем из датасета категорийные признаки с корреляцией >0.7\ndf_dop.drop(['education_3', 'work_address_3', 'home_address_1', 'wealthe_2'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Корректируем список с числовыми признаками\nnum_cols_cor = num_cols_new.copy()\nnum_cols_cor.remove('bki_request_cnt')  # Убираем признак \"bki_request_cnt\"\nnum_cols_cor.remove('decline_app_cnt')  # Убираем признак \"decline_app_cnt\"\nnum_cols_cor.remove('income')  # Убираем признак \"income\", так вместо него мы ввели категориальный признак \"wealthe\"\nnum_cols_cor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиваем датасет на тренировочный и тестовый, удалив лишние столбцы\ntrain_data_dop = df_dop.query('sample == 1').drop(['sample', 'client_id'], axis=1)  # Тренировочный\ntest_data_dop = df_dop.query('sample == 0').drop(['sample', 'default'], axis=1)     # Тестовый\n\n# Удаляем ID клиентов из тестового набора для последующего формирования признакового проостранства\ntest_data_dop.drop(['client_id'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Стандартизируем числовые данные\n\n# Тренировочный датасет\nX_num_train = StandardScaler().fit_transform(train_data_dop[num_cols_cor].values)\n#X_num_train = RobustScaler().fit_transform(train_data_dop[num_cols_cor].values)\n\n# Тестовый датасет\nX_num_test = StandardScaler().fit_transform(test_data_dop[num_cols_cor].values)\n#X_num_test = RobustScaler().fit_transform(test_data_dop[num_cols_cor].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Формируем датасеты с категориальными переменными\n\n# Тренировочный датасет\ndf_cat_train = train_data_dop.drop(['default'], axis = 1)\ndf_cat_train.drop(num_cols_new, axis = 1, inplace = True)\n\n# Тестовый датасет\ndf_cat_test = test_data_dop.drop(num_cols_new, axis = 1)\n\n\n# Объединяем цифровые, бинарные и категориальные оцифрованные признаки в одну матрицу (в одно признаковое пространство)\nX_4 = np.hstack([X_num_train, df_cat_train.values])\nX_t_4 = np.hstack([X_num_test, df_cat_test.values])\n\n# Целевая переменная\ny_4 = train_data_dop['default'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиваем данные на тренировочную и тестовую части\nX_train, X_test, y_train, y_test = train_test_split(X_4, y_4, test_size=0.2, shuffle = True, random_state=RANDOM_SEED)\n\nmodel_4 = LogisticRegression(multi_class = 'ovr', class_weight='balanced', solver='liblinear', random_state=RANDOM_SEED)\nmodel_4.fit(X_train, y_train)\n\ny_pred = model_4.predict(X_test)\nprobs = model_4.predict_proba(X_test)\n\n# Визуализация результатов\nmodel_visual(y_pred, probs, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Регуляризация построенной модели\nmodel_4_1 = G_S_CV(model_4, param_grid_1, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_4_2 = G_S_CV(model_4, param_grid_2, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ВЫВОДЫ (модели №№ 4 и 4.1):\n### После добавления новых признаков, значения метрик стали лучше, чем у базовой модели (модель №1), и немного хуже, чем в модели №3 "},{"metadata":{},"cell_type":"markdown","source":"## Модель №5 (модель с новыми признаками (модель №4) + очистка от выбросов)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_clear = train_data_dop.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проводим очистку числовых признаков за исключением признака \"decline_app_cnt\"\n#column = ['app_date', 'score_bki', 'income', 'reliability']\ncolumn = ['app_date', 'score_bki', 'reliability']\nfor i in column:\n    clear_sign_num(df_clear, i)\n\n# Стандартизируем числовые переменные методом StandardScaler\n\n# Тренировочный датасет\nX_num_train = StandardScaler().fit_transform(df_clear[num_cols_cor].values)\n#X_num_train = RobustScaler().fit_transform(df_clear[num_cols_cor].values)\n\n# Тестовый датасет\nX_num_test = StandardScaler().fit_transform(test_data_dop[num_cols_cor].values)\n#X_num_test = RobustScaler().fit_transform(test_data_dop[num_cols_cor].values)\n\n\n# Формируем датасеты с категориальными переменными\n\n# Тренировочный датасет\ndf_cat_train = df_clear.drop(num_cols_new, axis = 1)\ndf_cat_train.drop([\"default\"], axis = 1, inplace = True)\n\n# Тестовый датасет\ndf_cat_test = test_data_dop.drop(num_cols_new, axis = 1)\n\n\n# Объединяем цифровые, бинарные и категориальные оцифрованные признаки в одну матрицу (в одно признаковое пространство)\n\n# Тренировочные данные\nX_5 = np.hstack([X_num_train, df_cat_train.values])\n\n# Тестовые данные\nX_t_5 = np.hstack([X_num_test, df_cat_test.values])\n\n# Целевая переменная\ny_5 = df_clear['default'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Разбиваем данные на тренировочную и тестовую части\nX_train, X_test, y_train, y_test = train_test_split(X_5, y_5, test_size=0.2, shuffle = True, random_state=RANDOM_SEED)\n\nmodel_5 = LogisticRegression(multi_class = 'ovr', class_weight='balanced', solver='liblinear', random_state=RANDOM_SEED)\nmodel_5.fit(X_train, y_train)\n\n# Предсказываем целевую переменную и вероятностные оценки\ny_pred = model_5.predict(X_test)\nprobs = model_5.predict_proba(X_test)\n\n# Визуализация результатов\nmodel_visual(y_pred, probs, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Регуляризация построенной модели\nmodel_5_1 = G_S_CV(model_5, param_grid_1, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ВЫВОДЫ (модели №№ 5 и 5.1):\n### После включения в состав модели новых признаков и очистки от выбросов значение ROC AUC стало равным 0.74891 (максимальным из всех моделей)"},{"metadata":{},"cell_type":"markdown","source":"## Таким образом, модель 5.1 является самой лучшей моделью по значениям метрик, однако, на соревновании показывает плохие результаты. Очвидно, после очистки признаков от выбросов, происходит переобучение модели. Поэтому, для соревнования (создания файла SUBMISSION) целесообразно использовать модель 4.1."},{"metadata":{},"cell_type":"markdown","source":"# SUBMISSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model_4_1.predict_proba(X_t_4)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'client_id': id_test, \n                            'default': predict_submission})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ПОДВАЛ"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}